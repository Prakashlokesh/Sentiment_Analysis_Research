{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6113eb-352a-44a5-b504-e79bdf1806d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas tqdm openpyxl\n",
    "pip install textblob\n",
    "pip install nltk\n",
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496421e-632a-4a05-b886-486fba03ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(\"/Users/prakashreddy/Documents/Grad_Project/LAPD_Police_Data_Cleaned.xlsx\")\n",
    "\n",
    "# Initialize VADER analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to classify sentiment\n",
    "def get_vader_sentiment(text):\n",
    "    scores = vader_analyzer.polarity_scores(str(text))\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        return \"POSITIVE\"\n",
    "    elif compound <= -0.05:\n",
    "        return \"NEGATIVE\"\n",
    "    else:\n",
    "        return \"NEUTRAL\"\n",
    "\n",
    "# Apply VADER sentiment to all cleaned_text rows\n",
    "tqdm.pandas(desc=\"VADER Sentiment\")\n",
    "df[\"vader_sentiment\"] = df[\"Cleaned_Text\"].astype(str).progress_apply(get_vader_sentiment)\n",
    "\n",
    "# Save updated file\n",
    "df.to_excel(\"/Users/prakashreddy/Documents/LAPD_with_vader_sentiment.xlsx\", index=False)\n",
    "print(\"✅ VADER sentiment analysis complete. File saved as 'LAPD_with_vader_sentiment.xlsx'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339441e1-a3ca-4a35-9443-4a7bbbbd9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your Excel file\n",
    "df = pd.read_excel(\"/Users/prakashreddy/Documents/Grad_Project/LAPD_Police_Data_Cleaned.xlsx\")\n",
    "\n",
    "# Ensure required column exists\n",
    "if \"hf_sentiment\" not in df.columns:\n",
    "    df[\"hf_sentiment\"] = None\n",
    "    df[\"hf_confidence\"] = None\n",
    "\n",
    "# Filter rows missing Hugging Face sentiment\n",
    "missing_mask = df[\"hf_sentiment\"].isna()\n",
    "texts_to_analyze = df.loc[missing_mask, \"Cleaned_Text\"].astype(str).tolist()\n",
    "\n",
    "# Initialize Hugging Face sentiment classifier\n",
    "hf_classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Analyze each tweet using Hugging Face\n",
    "hf_sentiments = []\n",
    "hf_confidences = []\n",
    "\n",
    "for text in tqdm(texts_to_analyze, desc=\"Hugging Face Sentiment\"):\n",
    "    try:\n",
    "        result = hf_classifier(text[:512])[0]  # Truncate to 512 characters\n",
    "        hf_sentiments.append(result[\"label\"])\n",
    "        hf_confidences.append(result[\"score\"])\n",
    "    except Exception:\n",
    "        hf_sentiments.append(None)\n",
    "        hf_confidences.append(None)\n",
    "\n",
    "# Assign results back to the DataFrame\n",
    "df.loc[missing_mask, \"hf_sentiment\"] = hf_sentiments\n",
    "df.loc[missing_mask, \"hf_confidence\"] = hf_confidences\n",
    "\n",
    "# Save to a new Excel file\n",
    "df.to_excel(\"/Users/prakashreddy/Documents/LAPD_with_hf_sentiment.xlsx\", index=False)\n",
    "print(\"✅ Hugging Face sentiment analysis complete. Saved as 'LAPD_with_hf_sentiment.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a520096f-3d6b-4ef8-bd6e-e947a012c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Hugging Face Sentiment: 100%|████████████| 60894/60894 [09:09<00:00, 110.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sentiment analysis complete with custom logic. File saved as 'LAPD_with_hf_sentiment_custom_logic.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load your Excel file\n",
    "df = pd.read_excel(\"/Users/prakashreddy/Documents/Grad_Project/Preprocessed Data/LAPD_Police_Data_Cleaned.xlsx\")\n",
    "\n",
    "# Ensure required columns exist\n",
    "if \"hf_sentiment\" not in df.columns:\n",
    "    df[\"hf_sentiment\"] = None\n",
    "    df[\"hf_confidence\"] = None\n",
    "\n",
    "# Filter rows missing Hugging Face sentiment\n",
    "missing_mask = df[\"hf_sentiment\"].isna()\n",
    "texts_to_analyze = df.loc[missing_mask, \"Cleaned_Text\"].astype(str).tolist()\n",
    "\n",
    "# Initialize Hugging Face sentiment classifier\n",
    "hf_classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Analyze each tweet using Hugging Face\n",
    "hf_sentiments = []\n",
    "hf_confidences = []\n",
    "\n",
    "for text in tqdm(texts_to_analyze, desc=\"Hugging Face Sentiment\"):\n",
    "    try:\n",
    "        result = hf_classifier(text[:512])[0]  # Truncate to 512 characters\n",
    "        label = result[\"label\"]\n",
    "        score = result[\"score\"]\n",
    "\n",
    "        \n",
    "        if label == \"POSITIVE\" and score > 0.6:\n",
    "            sentiment = \"positive\"\n",
    "        elif label == \"NEGATIVE\" and score > 0.6:\n",
    "            sentiment = \"negative\"\n",
    "        elif score <= 0.6:\n",
    "            sentiment = \"neutral\"\n",
    "\n",
    "\n",
    "        hf_sentiments.append(sentiment)\n",
    "        hf_confidences.append(score)\n",
    "    except Exception:\n",
    "        hf_sentiments.append(None)\n",
    "        hf_confidences.append(None)\n",
    "\n",
    "# Assign results back to the DataFrame\n",
    "df.loc[missing_mask, \"hf_sentiment\"] = hf_sentiments\n",
    "df.loc[missing_mask, \"hf_confidence\"] = hf_confidences\n",
    "\n",
    "# Save to a new Excel file\n",
    "df.to_excel(\"/Users/prakashreddy/Documents/NYPD_with_hf_sentiment_custom_logic.xlsx\", index=False)\n",
    "print(\"✅ Sentiment analysis complete with custom logic. File saved as 'LAPD_with_hf_sentiment_custom_logic.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e636e4d-028d-4e97-887e-4485c384574e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetnlp",
   "language": "python",
   "name": "tweetnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
